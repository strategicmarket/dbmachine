

WHY AI CANNOT REASON WHY

WSJ May 18

Mr. Judea Pearl is a professor of computer science at UCLA and winner of the 2011 Turing Award for his work on probabilistic and causal reasoning. He and Mr. Dana Mackenzie, a mathematics writer, are co-authors of “The Book of Why: The Science of Cause and Effect,” just published by Basic Books


also see axiom of choice
------
Computer programs have reached a bewildering point in their long and unsteady journey toward artificial intelligence. They outperform people at tasks we once felt to be uniquely human, such as playing poker or recognizing faces in a crowd. Meanwhile, self-driving cars using similar technology run into pedestrians and posts and we wonder whether they can ever be trustworthy.

Amid these rapid developments and nagging setbacks, one essential building block of human intelligence has eluded machines for decades: Understanding cause and effect.

Put simply, today’s machine-learning programs can’t tell whether a crowing rooster makes the sun rise, or the other way around. Whatever volumes of data a machine analyzes, it cannot understand what a human gets intuitively.

Machine-learning systems have made astounding progress at analyzing data patterns, but that is the low-hanging fruit of artificial intelligence. To reach the higher fruit, AI needs a ladder, which we call the Ladder of Causation. Its rungs represent three levels of reasoning.

The first rung is Association, the level for current machines and many animals; on that rung, Pavlov’s dogs learned to associate a bell with food. The next is Intervention: What will happen if I ring a bell, or raise the price of toothpaste? Intervention is different from observation; raising the price unilaterally is different from seeing what happened in the past. The top rung is Counterfactual, which means the ability to imagine results, reflect on one’s actions and assess other scenarios. This is the rung that machines need to reach to evaluate and communicate about responsibility, credit, blame and self-improvement. Imagine giving a self-driving car this ability. After an accident, its CPU would ask itself questions like: What would have happened if I had not honked at the drunken pedestrian?

To reach the higher rungs, in place of ever-more data, machines need a model of the underlying causal factors—essentially, a mathematics of cause and effect.

Current machine learning systems can reach higher rungs only in circumscribed domains where the rules are inviolate, such as playing chess. Outside those domains, they are brittle and mistake-prone. But with causal models, a machine can predict the results of actions that haven’t been tried before, reflect on its actions, and transfer its learned skills to new situations


























